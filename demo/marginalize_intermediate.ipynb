{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import hashlib\n",
    "\n",
    "import datasets\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import torch\n",
    "import vec2text \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def compute_cosine_similarity(embeddings1, embeddings2):\n",
    "    return torch.nn.functional.cosine_similarity(embeddings1, embeddings2, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for error analysis\n",
    "\n",
    "Let's take the first $n=100$ rows of the precomputed val dataset for MS MARCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES=100\n",
    "dataset = datasets.load_dataset(\"jxm/msmarco__openai_ada2\")\n",
    "dataset = dataset[\"train\"].select(range(N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "MAX_LENGTH=128\n",
    "\n",
    "def truncate_text(example):\n",
    "    text_tokens = tokenizer.encode_batch(example[\"text\"])\n",
    "    text_tokens = [tok[:MAX_LENGTH] for tok in text_tokens]\n",
    "    text_list = tokenizer.decode_batch(text_tokens)\n",
    "    example[\"text\"] = text_list\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=12): 100%|██████████| 100/100 [00:00<00:00, 806.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(truncate_text, batched=True, batch_size=1024, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=12): 100%|██████████| 100/100 [00:00<00:00, 865.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Assumes no batching\n",
    "def get_text_hash(example):\n",
    "    example[\"source_id\"] = hashlib.md5(example[\"text\"].encode()).hexdigest()\n",
    "    return example\n",
    "    \n",
    "\n",
    "dataset = dataset.map(get_text_hash, batched=False, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(name=\"step\", column=[0] * N_SAMPLES)\n",
    "dataset = dataset.add_column(name=\"sim\", column=[1] * N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/nlp/vec2text/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/ritsuko/ai/nlp/vec2text/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "corrector = vec2text.load_pretrained_corrector(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction trajectory at n_steps=10 \n",
    "# Assume non-batched\n",
    "def get_trajectory(n_steps, examples):\n",
    "    new_examples = {k: [] for k in examples.keys()}\n",
    "\n",
    "    for i, original_embedding in enumerate(examples[\"embeddings_A\"]):\n",
    "        original_embedding = torch.Tensor(original_embedding).cuda().unsqueeze(0)\n",
    "\n",
    "\n",
    "        output_strings, hypothesis_embeddings = vec2text.invert_embeddings_and_return_hypotheses(original_embedding, corrector, num_steps=n_steps, sequence_beam_width=4)\n",
    "\n",
    "        # Append to example\n",
    "        new_examples[\"source_id\"] += [examples[\"source_id\"][i] for _ in range(len(hypothesis_embeddings))]\n",
    "        new_examples[\"text\"] += [output[0] for output in output_strings]\n",
    "        new_examples[\"embeddings_A\"] += [emb.squeeze().tolist() for emb in hypothesis_embeddings]\n",
    "        new_examples[\"step\"] += range(1, len(hypothesis_embeddings) + 1)\n",
    "        new_examples[\"sim\"] += [compute_cosine_similarity(original_embedding, embedding).item() for embedding in hypothesis_embeddings]\n",
    "\n",
    "    return {k: examples[k] + new_examples[k] for k in examples.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:01<00:00,  1.77s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['The scientific success of the Manhattan Project was as much a matter of communication as of the lives of thousands of scientists and engineers. What was truly meaningless was the utter lack of a doubt that the atomic bombs had a profoundly influential and awe-inspiring impact upon the lives of their fellow scientists.', 'The presence of communication among the scientists and engineers of the Manhattan Project was as important a means to their success as it was a means to their success. What was literally meaningless was the utter oblivion of hundreds of thousands of innocent lives in the atomic cradle; however, the scientific achievement had a profound impact.'], 'embeddings_A': 'Mock', 'source_id': ['8bd034ea81f91372874cf6d90dffbba1', '8bd034ea81f91372874cf6d90dffbba1'], 'step': [1, 2], 'sim': [0.9612681269645691, 0.9714975953102112]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'embeddings_A', 'source_id', 'step', 'sim'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(range(1)).map(partial(get_trajectory, 1), batched=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
