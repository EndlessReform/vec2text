{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/nlp/vec2text/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import hashlib\n",
    "\n",
    "import datasets\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import torch\n",
    "import vec2text \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def compute_cosine_similarity(embeddings1, embeddings2):\n",
    "    return torch.nn.functional.cosine_similarity(embeddings1, embeddings2, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for error analysis\n",
    "\n",
    "Let's take the first $n=100$ rows of the precomputed val dataset for MS MARCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES=100\n",
    "dataset = datasets.load_dataset(\"jxm/msmarco__openai_ada2\")\n",
    "dataset = dataset[\"train\"].select(range(N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "MAX_LENGTH=128\n",
    "\n",
    "def truncate_text(example):\n",
    "    text_tokens = tokenizer.encode_batch(example[\"text\"])\n",
    "    text_tokens = [tok[:MAX_LENGTH] for tok in text_tokens]\n",
    "    text_list = tokenizer.decode_batch(text_tokens)\n",
    "    example[\"text\"] = text_list\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=12): 100%|██████████| 100/100 [00:00<00:00, 713.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(truncate_text, batched=True, batch_size=1024, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=12): 100%|██████████| 100/100 [00:00<00:00, 715.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Assumes no batching\n",
    "def get_text_hash(example):\n",
    "    example[\"source_id\"] = hashlib.md5(example[\"text\"].encode()).hexdigest()\n",
    "    return example\n",
    "    \n",
    "\n",
    "dataset = dataset.map(get_text_hash, batched=False, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(name=\"step\", column=[0] * N_SAMPLES)\n",
    "dataset = dataset.add_column(name=\"sim\", column=[1] * N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/nlp/vec2text/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/ritsuko/ai/nlp/vec2text/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "corrector = vec2text.load_pretrained_corrector(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction trajectory at n_steps=10 \n",
    "# Assume non-batched\n",
    "def get_trajectory(n_steps, examples):\n",
    "    new_examples = {k: [] for k in examples.keys()}\n",
    "\n",
    "    for i, original_embedding in enumerate(examples[\"embeddings_A\"]):\n",
    "        original_embedding = torch.Tensor(original_embedding).cuda().unsqueeze(0)\n",
    "\n",
    "\n",
    "        output_strings, hypothesis_embeddings = vec2text.invert_embeddings_and_return_hypotheses(original_embedding, corrector, num_steps=n_steps, sequence_beam_width=4)\n",
    "\n",
    "        # Append to example\n",
    "        new_examples[\"source_id\"] += [examples[\"source_id\"][i] for _ in range(len(hypothesis_embeddings))]\n",
    "        new_examples[\"text\"] += [output[0] for output in output_strings]\n",
    "        new_examples[\"embeddings_A\"] += [emb.squeeze().tolist() for emb in hypothesis_embeddings]\n",
    "        new_examples[\"step\"] += range(1, len(hypothesis_embeddings) + 1)\n",
    "        new_examples[\"sim\"] += [compute_cosine_similarity(original_embedding, embedding).item() for embedding in hypothesis_embeddings]\n",
    "\n",
    "    return {k: examples[k] + new_examples[k] for k in examples.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [2:01:31<00:00, 72.91s/ examples]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset.select(range(100)).map(partial(get_trajectory, 50), batched=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.sort(\"source_id\").sort(\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 180.96ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1849366"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_dataset.to_csv('test.csv', index=False)\n",
    "test_dataset.remove_columns(['embeddings_A']).to_csv(\"test_50_no_emb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 30.20ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65762328"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.to_parquet(\"test_50_emb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8bd034ea81f91372874cf6d90dffbba1',\n",
       " '41ff020092780cbe3f0bb1a19af9a9bb',\n",
       " 'b41462004c2f175c26b021580d52ebdb',\n",
       " 'ee1c1f0fd5e5b4d8c57b5f7ce4a524c7',\n",
       " 'd320cf0dec7398aff7157ae6bf50d95a',\n",
       " '43d708365012811206eae310f234d268',\n",
       " '0251de9b50ca73ac3f2f8d0b1d8f6b7b',\n",
       " 'aab5f71e8417e4e22dde53048c8aee21',\n",
       " '85d7a4ce47403d7eb621eb2814069bec',\n",
       " 'adc5c918b742688fa96a7da70fce56d4']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.unique(\"source_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 120/120 [00:00<00:00, 2324.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "example = test_dataset.filter(lambda example: example['source_id'] == \"8bd034ea81f91372874cf6d90dffbba1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
